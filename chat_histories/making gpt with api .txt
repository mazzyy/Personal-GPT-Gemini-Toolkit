user: bakend
def load_chat_history(topic):
    history = []
    file_path = os.path.join(chat_dir, f"{topic}.txt")
    print(file_path)
    
    if os.path.exists(file_path):
        with open(file_path, "r") as f:
            # Read the entire file content
            content = f.read()
            
            # Use regex to find all instances of "
user: " and "
AI: " and split the content accordingly
            messages = re.split(r"(
user: |
AI: )", content)
            
            # Iterate through the split content to parse messages
            current_role = None
            for message in messages:
                message = message.strip()
                
                if message == "
user: ":
                    current_role = "user"
                    print(current_role)
                elif message == "
AI: ":
                    current_role = "AI"
                    print(current_role)

                elif current_role and message:
                    if current_role == "user":
                        history.append(HumanMessage(content=message))
                    elif current_role == "AI":
                        history.append(AIMessage(content=message))
                    current_role = None
    
    return history
frontend part
 <h4 id="current-topic">Chat History</h4>
                <div id="chat-history" class="card mb-3">
                    <div class="card-body" style="height: 400px; overflow-y: scroll;">
                        <!-- Chat history will be displayed here -->
                    </div>
                </div>

it should have frontend look like 
how .txt is formated is space is in line it shiould have space here a if code of a format then it should show code format example
user: encoder and decoder
AI: An encoder and decoder are commonly used terms in the field of digital communications and data processing. 

1. Encoder: An encoder is a device or program that converts data from one format to another before it's transmitted. In the context of machine learning, an encoder could refer to the part of an autoencoder that compresses the input into a latent space representation. It reduces the dimensionality of the input data and extracts useful features from it. 

2. Decoder: A decoder is a device or program that does the reverse operation of an encoder, it translates the encoded data back into its original format. In the context of machine learning, a decoder could refer to the part of an autoencoder that reconstructs the input from the latent space representation.

In the world of natural language processing (NLP), the terms "encoder" and "decoder" are often used to describe components of models used for tasks like machine translation or text generation. The encoder processes the input data and the decoder generates the output data. For example, in a machine translation task, the encoder processes the source language and the decoder generates the translation in the target language.
user: generate pytorch code for encoder
AI: Creating an encoder can vary greatly depending on the specific use case and model architecture. Here is a simple example of a PyTorch code for an encoder which is part of an autoencoder. This encoder reduces the dimensionality of the input data from 784 to a latent space of dimension 128.

```python
import torch
from torch import nn

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.fc1 = nn.Linear(784, 256)
        self.fc2 = nn.Linear(256, 128)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        return x

encoder = Encoder()
```

In this code:

- We define the Encoder class that inherits from the PyTorch nn.Module class.
- We define two fully connected layers (nn.Linear) in the initializer (__init__ method), which will be used to reduce the dimensionality of the input data.
- We also define a ReLU activation function which introduces non-linearity into the model.
- In the forward method, we pass the input through the layers and activation function.
  
Please modify this code according to your exact requirements.
AI: Your backend function `load_chat_history(topic)` seems to be reading a text file containing a chat history between a user and an AI. It uses regular expressions to split the file into individual messages and to identify whether a message was sent by the user or the AI. The function then constructs a list of `HumanMessage` and `AIMessage` objects (presumably defined elsewhere in your code) representing the chat history.

For the frontend part, you're using HTML to construct a user interface where the chat history will be displayed. The `<h4>` tag is used to display the title, and the `<div>` tag is used to create a scrollable area where the chat messages will be displayed.

The chat history example you've given seems to be a typical interaction between a user and an AI about a specific topic (in this case, encoders and decoders). The chat history is well-structured, with clear indications of who sent each message and well-formatted responses from the AI (including the use of markdown to format a block of Python code).

In order to display this chat history on your frontend, you would need to add some JavaScript (or use a frontend framework) to fetch the chat history from the backend and add it to the HTML document. You may also need to write some CSS to style the chat messages and differentiate between messages sent by the user and the AI.
user: generate code to handle this
AI: Sure, here's a simple example of how you might fetch the chat history from your server and add it to your HTML document using JavaScript and AJAX. Note that this assumes your server provides an endpoint (e.g., `/get_chat_history`) that returns the chat history in a JSON format when given a `topic` parameter.

```html
<h4 id="current-topic">Chat History</h4>
<div id="chat-history" class="card mb-3">
    <div class="card-body" style="height: 400px; overflow-y: scroll;">
        <!-- Chat history will be displayed here -->
    </div>
</div>

<script>
// Fetch chat history from server
fetch('/get_chat_history?topic=encoder_and_decoder')
    .then(response => response.json())
    .then(chatHistory => {
        // Get chat history container
        const chatHistoryContainer = document.querySelector('#chat-history .card-body');

        // Add chat messages to container
        chatHistory.forEach(message => {
            const messageElement = document.createElement('p');
            messageElement.textContent = `${message.sender}: ${message.content}`;
            chatHistoryContainer.appendChild(messageElement);
        });
    })
    .catch(error => console.error('Error:', error));
</script>
```

This code uses the Fetch API to send a request to the `/get_chat_history` endpoint on your server, passing the `topic` parameter in the query string. It then processes the response, assuming it is a JSON object where each chat message is represented as an object with `sender` and `content` properties. Each chat message is added to the `chat-history` container as a new `<p>` element.

Please note that this is a basic example and you might need to adjust this code according to your specific needs and setup. For example, you might need to add error handling to deal with situations where the server is unavailable or returns an error. You might also need to adjust the URL of the endpoint if your server is not running on the same domain. Finally, you might want to add more complex formatting or styling to the chat messages.
user: exit 
AI: Okay, if you have any other questions in the future, feel free to ask. Goodbye!
